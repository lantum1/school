{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ ---------\n",
      "aiohttp            3.8.3\n",
      "aiosignal          1.2.0\n",
      "asttokens          2.0.8\n",
      "async-timeout      4.0.2\n",
      "attrs              22.1.0\n",
      "backcall           0.2.0\n",
      "certifi            2022.9.24\n",
      "charset-normalizer 2.1.1\n",
      "colorama           0.4.5\n",
      "datasets           2.6.1\n",
      "debugpy            1.6.3\n",
      "decorator          5.1.1\n",
      "dill               0.3.5.1\n",
      "entrypoints        0.4\n",
      "executing          1.0.0\n",
      "filelock           3.8.0\n",
      "frozenlist         1.3.1\n",
      "fsspec             2022.8.2\n",
      "huggingface-hub    0.10.0\n",
      "idna               3.4\n",
      "ipykernel          6.15.3\n",
      "ipython            8.5.0\n",
      "jedi               0.18.1\n",
      "joblib             1.2.0\n",
      "jupyter_client     7.3.5\n",
      "jupyter-core       4.11.1\n",
      "matplotlib-inline  0.1.6\n",
      "multidict          6.0.2\n",
      "multiprocess       0.70.13\n",
      "nest-asyncio       1.5.5\n",
      "numpy              1.23.3\n",
      "packaging          21.3\n",
      "pandas             1.5.0\n",
      "parso              0.8.3\n",
      "pickleshare        0.7.5\n",
      "Pillow             9.2.0\n",
      "pip                22.2.1\n",
      "prompt-toolkit     3.0.31\n",
      "psutil             5.9.2\n",
      "pure-eval          0.2.2\n",
      "pyarrow            9.0.0\n",
      "Pygments           2.13.0\n",
      "pyparsing          3.0.9\n",
      "python-dateutil    2.8.2\n",
      "pytz               2022.4\n",
      "pywin32            304\n",
      "PyYAML             6.0\n",
      "pyzmq              23.2.1\n",
      "regex              2022.9.13\n",
      "requests           2.28.1\n",
      "responses          0.18.0\n",
      "scikit-learn       1.1.2\n",
      "scipy              1.9.2\n",
      "setuptools         63.2.0\n",
      "six                1.16.0\n",
      "sklearn            0.0\n",
      "stack-data         0.5.0\n",
      "threadpoolctl      3.1.0\n",
      "tokenizers         0.12.1\n",
      "torch              1.12.1\n",
      "torchaudio         0.12.1\n",
      "torchvision        0.13.1\n",
      "tornado            6.2\n",
      "tqdm               4.64.1\n",
      "traitlets          5.4.0\n",
      "transformers       4.22.2\n",
      "typing_extensions  4.4.0\n",
      "urllib3            1.26.12\n",
      "wcwidth            0.2.5\n",
      "xxhash             3.0.0\n",
      "yarl               1.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 4.23.1\n",
      "torch 1.12.1+cu116\n",
      "datasets 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import transformers, torch, datasets\n",
    "print(\"transformers\", transformers.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"datasets\", datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.77k/3.77k [00:00<00:00, 1.08MB/s]\n",
      "Downloading metadata: 100%|██████████| 1.85k/1.85k [00:00<00:00, 644kB/s]\n",
      "Downloading readme: 100%|██████████| 4.61k/4.61k [00:00<00:00, 1.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sst2/default (download: 7.09 MiB, generated: 4.78 MiB, post-processed: Unknown size, total: 11.88 MiB) to /home/lantum/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 7.44M/7.44M [00:01<00:00, 5.29MB/s]\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sst2 downloaded and prepared to /home/lantum/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 188.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "dataset = load_dataset(\"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 466k/466k [00:01<00:00, 239kB/s] \n",
      " 99%|█████████▊| 67/68 [00:01<00:00, 34.89ba/s]\n",
      "  0%|          | 0/1 [00:00<?, ?ba/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00, 11.06ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"~/test\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 67349\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6315\n",
      "  0%|          | 5/6315 [00:02<51:50,  2.03it/s]\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: sentence, idx. If sentence, idx are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "  8%|▊         | 500/6315 [03:03<32:15,  3.00it/s]Saving model checkpoint to /home/lantum/test/checkpoint-500\n",
      "Configuration saved in /home/lantum/test/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3227, 'learning_rate': 9.154394299287412e-06, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-500/special_tokens_map.json\n",
      " 16%|█▌        | 1000/6315 [06:09<31:32,  2.81it/s] Saving model checkpoint to /home/lantum/test/checkpoint-1000\n",
      "Configuration saved in /home/lantum/test/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2356, 'learning_rate': 8.362628661916074e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-1000/special_tokens_map.json\n",
      " 24%|██▍       | 1500/6315 [09:16<30:29,  2.63it/s]Saving model checkpoint to /home/lantum/test/checkpoint-1500\n",
      "Configuration saved in /home/lantum/test/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2184, 'learning_rate': 7.570863024544736e-06, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-1500/special_tokens_map.json\n",
      " 32%|███▏      | 2000/6315 [12:23<26:16,  2.74it/s]Saving model checkpoint to /home/lantum/test/checkpoint-2000\n",
      "Configuration saved in /home/lantum/test/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1988, 'learning_rate': 6.779097387173397e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-2000/special_tokens_map.json\n",
      " 40%|███▉      | 2500/6315 [15:29<21:22,  2.97it/s]Saving model checkpoint to /home/lantum/test/checkpoint-2500\n",
      "Configuration saved in /home/lantum/test/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1538, 'learning_rate': 5.987331749802059e-06, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-2500/special_tokens_map.json\n",
      " 48%|████▊     | 3000/6315 [18:35<18:54,  2.92it/s]Saving model checkpoint to /home/lantum/test/checkpoint-3000\n",
      "Configuration saved in /home/lantum/test/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1459, 'learning_rate': 5.195566112430721e-06, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-3000/special_tokens_map.json\n",
      " 55%|█████▌    | 3500/6315 [21:41<17:59,  2.61it/s]Saving model checkpoint to /home/lantum/test/checkpoint-3500\n",
      "Configuration saved in /home/lantum/test/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1412, 'learning_rate': 4.403800475059382e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-3500/special_tokens_map.json\n",
      " 63%|██████▎   | 4000/6315 [24:47<13:48,  2.79it/s]Saving model checkpoint to /home/lantum/test/checkpoint-4000\n",
      "Configuration saved in /home/lantum/test/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1373, 'learning_rate': 3.612034837688045e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-4000/special_tokens_map.json\n",
      " 71%|███████▏  | 4500/6315 [27:53<11:09,  2.71it/s]Saving model checkpoint to /home/lantum/test/checkpoint-4500\n",
      "Configuration saved in /home/lantum/test/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1266, 'learning_rate': 2.8202692003167065e-06, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-4500/special_tokens_map.json\n",
      " 79%|███████▉  | 5000/6315 [30:58<07:33,  2.90it/s]Saving model checkpoint to /home/lantum/test/checkpoint-5000\n",
      "Configuration saved in /home/lantum/test/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1148, 'learning_rate': 2.0285035629453685e-06, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-5000/special_tokens_map.json\n",
      " 87%|████████▋ | 5500/6315 [34:05<05:20,  2.54it/s]Saving model checkpoint to /home/lantum/test/checkpoint-5500\n",
      "Configuration saved in /home/lantum/test/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1034, 'learning_rate': 1.2367379255740302e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-5500/special_tokens_map.json\n",
      " 95%|█████████▌| 6000/6315 [37:12<02:06,  2.49it/s]Saving model checkpoint to /home/lantum/test/checkpoint-6000\n",
      "Configuration saved in /home/lantum/test/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1038, 'learning_rate': 4.4497228820269205e-07, 'epoch': 2.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /home/lantum/test/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/lantum/test/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /home/lantum/test/checkpoint-6000/special_tokens_map.json\n",
      "100%|██████████| 6315/6315 [39:11<00:00,  2.95it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 6315/6315 [39:11<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2351.3609, 'train_samples_per_second': 85.928, 'train_steps_per_second': 2.686, 'train_loss': 0.16430803904529612, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6315, training_loss=0.16430803904529612, metrics={'train_runtime': 2351.3609, 'train_samples_per_second': 85.928, 'train_steps_per_second': 2.686, 'train_loss': 0.16430803904529612, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение модели (обученной на 6315), я хз, что я сохраняю, я хз, как это загрузить в прогу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/home/lantum/test1/model.bin\")\n",
    "torch.save(model.state_dict(),\"/home/lantum/test1/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства использования модели в инференсе, можно переименовать параметры с помощью словарей label2id и id2label. Это позволит при выводе результатов, видеть классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/lantum/test/checkpoint-6000/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/home/lantum/test/checkpoint-6000\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"positive\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "label2id = {\n",
    "    \"negative\": 0,\n",
    "    \"positive\": 1,\n",
    "  }\n",
    "id2label = {\n",
    "    0: \"negative\",\n",
    "    1: \"positive\",\n",
    "  }\n",
    "model_ckpt = \"/home/lantum/test/checkpoint-6000\"\n",
    "config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем сохраненную модель (!здесь на 6000!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading weights file /home/lantum/test/checkpoint-6000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /home/lantum/test/checkpoint-6000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/lantum/test/checkpoint-6000\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/lantum/test/checkpoint-6000\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем предсказание модели на тестовом предложении test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example output SequenceClassifierOutput(loss=None, logits=tensor([[ 2.4995, -2.4793]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Artemiy Mazaev is a fucking asshole! I HATE HIM!\"\n",
    "\n",
    "tensor = tokenizer(text, padding=\"max_length\",  truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(\"Example output\", model(**tensor))\n",
    "\n",
    "logits = model(**tensor).logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
